{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Aula 004: Redes Neurais.ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/guilhermeaugusto9/sigmoidal/blob/master/02%20-%20Escola%20de%20Data%20Science/01%20-%20Notebooks/Aula_004_Redes_Neurais.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lmHE3cU40ARW"
      },
      "source": [
        "<p align=\"center\"><img src=\"https://raw.githubusercontent.com/carlosfab/escola-data-science/master/img/eds.png\" height=\"100px\"></p>\n",
        "\n",
        "# Aula 004: Redes Neurais\n",
        "\n",
        "Redes neurais (NN) são os blocos construtores fundamentais do Deep Learning. Sua popularidade se dá devido a capacidade de lidar com problemas altamente complexos, onde algoritmos tradicionais não foram capazes de obter sucesso.\n",
        "\n",
        "Entre as principais aplicações das NN estão os carros autônomos, reconhecimento de objetos em imagens, tradução entre idiomas, legendas automáticas em vídeos, entre outras.\n",
        "\n",
        "<p align=\"center\"><img src=\"https://raw.githubusercontent.com/carlosfab/escola-data-science/master/img/human-neuron.png\" height=\"400px\"></p>\n",
        "\n",
        "Como foi mencionado na apresentação de slides, as NN são inspiradas neurônios biológicos da vida real, aqueles que temos no nosso próprio sistema nervoso - aproximadamente 10 bilhões.\n",
        "\n",
        "Cada um dos nossos neurônios está conectado a cerca de 10 mil outros neurônios. A comunicação entre esses neurônios ocorre por meio de impulsos captados pelos dendritos. Na sequência, esses impulsos são transmitidos pelo corpo do neurônio, por meio do axônio, até atingirem os dendritos de neurônios vizinhos através de sinapses.\n",
        "\n",
        "<p align=\"center\"><img src=\"https://raw.githubusercontent.com/carlosfab/escola-data-science/master/img/simple-nn.png\" height=\"300px\"></p>\n",
        "\n",
        "Se ficou difícil de imaginar esse paralelo entre o mundo real e artificial, veja a imagem abaixa comparando redes neurais biológicas e artificiais, bio-inspirados:\n",
        "\n",
        "<p align=\"center\"><img src=\"https://raw.githubusercontent.com/carlosfab/escola-data-science/master/img/comparativo_nn.png\" height=\"250px\"></p>\n",
        "\n",
        "Abandonando um pouco \n",
        "\n",
        "Em um NN artificial, recebem-se valores $x_1, x_2, x_3$, jutamente com uma constante conhecida como *bias*, que são multiplicados por pesos $w_1, w_2, w_3, w_4$ e somados. Por fim, essa soma passa por uma função de ativação, que irá fornecer o *output*.\n",
        "\n",
        "Matematicamente, a saída (*output*) da NN pode ser escrita de várias formas diferentes. Tipicamente você irá encontrar  a forma matemática, escrita como uma única equação:\n",
        "\n",
        "$$\n",
        "\\hat{y} = g \\left(w_0 + \\sum_{i=1}^{m} x_iw_i \\right) \\\\\n",
        "$$\n",
        "\n",
        "ou podemos escrever a mesma coisa usando a Algebra Linear em termos de vetores e produtos escalares:\n",
        "\n",
        "$$\n",
        "\\hat{y} = g \\left( w_0 + X^T W \\right) \\\\\n",
        "$$\n",
        "\n",
        "$$\n",
        "\\begin{equation}\n",
        "\\begin{aligned}\n",
        "X&=\n",
        "    \\begin{bmatrix}\n",
        "        x_1 \\\\ \\vdots \\\\ x_2\n",
        "    \\end{bmatrix} \n",
        "&&W=\n",
        "    \\begin{bmatrix}\n",
        "        w_1 \\\\ \\vdots \\\\ w_m\n",
        "    \\end{bmatrix} \\\\\n",
        "\\end{aligned}\n",
        "\\end{equation}\n",
        "$$"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "irZAhbxor1mV"
      },
      "source": [
        "### Um exemplo de Rede Neural simples\n",
        "\n",
        "Veja a imagem abaixo, onde temos uma NN que recebe dois *inputs* e fornece um resultado de saída.\n",
        "\n",
        "<p align=\"center\"><img src=\"https://raw.githubusercontent.com/carlosfab/escola-data-science/master/img/exemplo-nn.png\" height=\"250px\"></p>\n",
        "\n",
        "Nessa situação acima temos:\n",
        "\n",
        "$$\n",
        "\\begin{equation}\n",
        "\\begin{aligned}\n",
        "X&=\n",
        "    \\begin{bmatrix}\n",
        "        x_1 \\\\ x_2\n",
        "    \\end{bmatrix} \n",
        "&&W=\n",
        "    \\begin{bmatrix}\n",
        "        -2 \\\\ \\\\ 5\n",
        "    \\end{bmatrix}\n",
        "&&w_0=1\n",
        "\\end{aligned}\n",
        "\\end{equation}\n",
        "$$\n",
        "\n",
        "Matematicamente, o resultado final $\\hat{y}$ poderia ser escrito como $\\hat{y} = g(1 - 2x_1 +5x_2)$. No entanto, isso resolve apenas uma parte do problema.\n",
        "\n",
        "O poder do *Deep Learning* está em usar a não-lineariedade para resolver problemas complexos. É aí que entra a **função de ativação**, tema muito amplo (e que terá uma aula exclusiva para ele).\n",
        "\n",
        "Vamos apenas assumir que será usada a **função sigmoidal** (e sua curva ***sigmoidal***) para fornecer à nossa NN essa tal não-lineariedade.\n",
        "\n",
        "$$\n",
        "g(z) = \\sigma(z) = \\frac{1}{1 + e^{-z}}\n",
        "$$\n",
        "\n",
        "Não entendeu essa questão da lineariedade? \n",
        "\n",
        "Visualmente, veja na figura abaixo (extraída do MIT) como a parte linear $w_0 + \\sum_{i=1}^{m} x_iw_i$ da nossa equação não conseguiria separar corretamente as classes, não importando quantas camadas de neurônios existissem.\n",
        "\n",
        "<p align=\"center\"><img src=\"https://raw.githubusercontent.com/carlosfab/escola-data-science/master/img/linear-vs-nao-linear.png\" height=\"250px\"></p>\n",
        "\n",
        "Já quando você utiliza essa parte linear dentro de uma função de ativação $\\sigma(w_0 + \\sum_{i=1}^{m} x_iw_i)$, possibilita que esse tipo de curva não-linear possa ocorrer."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ph4QuYgt1C9c",
        "outputId": "15443416-76a9-4dff-8b42-f7a6ab9c63af",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "# importar as bibliotecas necessárias\n",
        "%tensorflow_version 2.x\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "# configurações do notebook\n",
        "sns.set_style()\n",
        "\n",
        "# importar dataset simplificado (variáveis numéricas)\n",
        "from sklearn.datasets import fetch_california_housing"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "TensorFlow 2.x selected.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SOyF91p524wq",
        "outputId": "11667094-d8cc-4691-95b7-49d21fa4f52a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "# exemplo dado na aula de rede neural:\n",
        "def sigmoid(x): \n",
        "    return 1.0/(1 + np.exp(-x))\n",
        "\n",
        "# valores de input\n",
        "x1 = 10\n",
        "x2 = -2\n",
        "\n",
        "# soma de w0 + X.W\n",
        "res = 1 -2*x1 + 5*x2\n",
        "\n",
        "# função de ativação sigmoid\n",
        "yhat = sigmoid(res)\n",
        "print(yhat)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2.543665647376276e-13\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PCxQBzJu6lpX"
      },
      "source": [
        "## Redes Neurais ao *dataset* imobiliário da California"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Nh4GhirYK5g0"
      },
      "source": [
        "# importar o dataset e lista com nomes das features\n",
        "dataset = fetch_california_housing()\n",
        "features = dataset.feature_names\n",
        "\n",
        "# dividir entre treino, validação e teste\n",
        "X_train_original, X_test, y_train_original, y_test = train_test_split(dataset.data, dataset.target)\n",
        "X_train, X_valid, y_train, y_valid = train_test_split(X_train_original, y_train_original)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ECcHLMsGGRWV",
        "outputId": "0126dfd9-7543-49e8-853a-39619ae36bc2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        }
      },
      "source": [
        "# ver como ficaria em formato de DataFrame\n",
        "df = pd.DataFrame(X_train)\n",
        "df.columns = features\n",
        "df.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>MedInc</th>\n",
              "      <th>HouseAge</th>\n",
              "      <th>AveRooms</th>\n",
              "      <th>AveBedrms</th>\n",
              "      <th>Population</th>\n",
              "      <th>AveOccup</th>\n",
              "      <th>Latitude</th>\n",
              "      <th>Longitude</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>3.9028</td>\n",
              "      <td>25.0</td>\n",
              "      <td>5.470968</td>\n",
              "      <td>0.987097</td>\n",
              "      <td>436.0</td>\n",
              "      <td>2.812903</td>\n",
              "      <td>39.52</td>\n",
              "      <td>-121.49</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>11.2160</td>\n",
              "      <td>36.0</td>\n",
              "      <td>8.443836</td>\n",
              "      <td>1.246575</td>\n",
              "      <td>771.0</td>\n",
              "      <td>2.112329</td>\n",
              "      <td>33.61</td>\n",
              "      <td>-117.91</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1.9063</td>\n",
              "      <td>21.0</td>\n",
              "      <td>4.463235</td>\n",
              "      <td>1.139706</td>\n",
              "      <td>226.0</td>\n",
              "      <td>1.661765</td>\n",
              "      <td>36.98</td>\n",
              "      <td>-122.02</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>4.0385</td>\n",
              "      <td>12.0</td>\n",
              "      <td>4.565574</td>\n",
              "      <td>0.981557</td>\n",
              "      <td>1122.0</td>\n",
              "      <td>2.299180</td>\n",
              "      <td>33.67</td>\n",
              "      <td>-117.99</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>3.2250</td>\n",
              "      <td>21.0</td>\n",
              "      <td>3.935484</td>\n",
              "      <td>1.163594</td>\n",
              "      <td>1099.0</td>\n",
              "      <td>2.532258</td>\n",
              "      <td>33.66</td>\n",
              "      <td>-117.91</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "    MedInc  HouseAge  AveRooms  ...  AveOccup  Latitude  Longitude\n",
              "0   3.9028      25.0  5.470968  ...  2.812903     39.52    -121.49\n",
              "1  11.2160      36.0  8.443836  ...  2.112329     33.61    -117.91\n",
              "2   1.9063      21.0  4.463235  ...  1.661765     36.98    -122.02\n",
              "3   4.0385      12.0  4.565574  ...  2.299180     33.67    -117.99\n",
              "4   3.2250      21.0  3.935484  ...  2.532258     33.66    -117.91\n",
              "\n",
              "[5 rows x 8 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sEbqJIGGGg7u"
      },
      "source": [
        "# padronizar os dados com StandardScaler por causa do Gradient Descent\n",
        "scaler = StandardScaler()\n",
        "X_train = scaler.fit_transform(X_train)\n",
        "X_test = scaler.transform(X_test)\n",
        "X_valid = scaler.transform(X_valid)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YKKeXLa1OIv0",
        "outputId": "a8823962-bfd6-40f0-d782-9a1db5e11469",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        }
      },
      "source": [
        "# ver o dataset padronizado\n",
        "pd.DataFrame(X_train).head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "      <th>1</th>\n",
              "      <th>2</th>\n",
              "      <th>3</th>\n",
              "      <th>4</th>\n",
              "      <th>5</th>\n",
              "      <th>6</th>\n",
              "      <th>7</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.011008</td>\n",
              "      <td>-0.291465</td>\n",
              "      <td>0.016340</td>\n",
              "      <td>-0.254890</td>\n",
              "      <td>-0.868446</td>\n",
              "      <td>-0.032641</td>\n",
              "      <td>1.822806</td>\n",
              "      <td>-0.955460</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>3.861743</td>\n",
              "      <td>0.585238</td>\n",
              "      <td>1.262597</td>\n",
              "      <td>0.354491</td>\n",
              "      <td>-0.574811</td>\n",
              "      <td>-0.149520</td>\n",
              "      <td>-0.948550</td>\n",
              "      <td>0.829391</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>-1.040240</td>\n",
              "      <td>-0.610267</td>\n",
              "      <td>-0.406112</td>\n",
              "      <td>0.103510</td>\n",
              "      <td>-1.052515</td>\n",
              "      <td>-0.224689</td>\n",
              "      <td>0.631733</td>\n",
              "      <td>-1.219698</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0.082461</td>\n",
              "      <td>-1.327569</td>\n",
              "      <td>-0.363211</td>\n",
              "      <td>-0.267899</td>\n",
              "      <td>-0.267152</td>\n",
              "      <td>-0.118347</td>\n",
              "      <td>-0.920414</td>\n",
              "      <td>0.789506</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>-0.345884</td>\n",
              "      <td>-0.610267</td>\n",
              "      <td>-0.627351</td>\n",
              "      <td>0.159612</td>\n",
              "      <td>-0.287312</td>\n",
              "      <td>-0.079462</td>\n",
              "      <td>-0.925104</td>\n",
              "      <td>0.829391</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "          0         1         2  ...         5         6         7\n",
              "0  0.011008 -0.291465  0.016340  ... -0.032641  1.822806 -0.955460\n",
              "1  3.861743  0.585238  1.262597  ... -0.149520 -0.948550  0.829391\n",
              "2 -1.040240 -0.610267 -0.406112  ... -0.224689  0.631733 -1.219698\n",
              "3  0.082461 -1.327569 -0.363211  ... -0.118347 -0.920414  0.789506\n",
              "4 -0.345884 -0.610267 -0.627351  ... -0.079462 -0.925104  0.829391\n",
              "\n",
              "[5 rows x 8 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bGNAfFA2Gw3n",
        "outputId": "893398e8-df6d-42f9-f572-8467a2b250fb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "# construir uma nn\n",
        "model = keras.models.Sequential(\n",
        "    [\n",
        "     keras.layers.Dense(30, activation='relu', input_shape=(X_train.shape[1:])),\n",
        "     keras.layers.Dense(1)\n",
        "    ]\n",
        ")\n",
        "\n",
        "# compilar a nn \n",
        "model.compile(loss='mean_squared_error', optimizer='sgd')\n",
        "\n",
        "# obter o histórico de loss\n",
        "history = model.fit(X_train, y_train, epochs=50, validation_data=(X_valid, y_valid))\n",
        "\n",
        "# verificar o MSE\n",
        "error = model.evaluate(X_test, y_test)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 11610 samples, validate on 3870 samples\n",
            "Epoch 1/50\n",
            "11610/11610 [==============================] - 1s 71us/sample - loss: 0.7691 - val_loss: 0.4773\n",
            "Epoch 2/50\n",
            "11610/11610 [==============================] - 1s 51us/sample - loss: 0.5383 - val_loss: 0.4286\n",
            "Epoch 3/50\n",
            "11610/11610 [==============================] - 1s 50us/sample - loss: 0.4690 - val_loss: 0.4083\n",
            "Epoch 4/50\n",
            "11610/11610 [==============================] - 1s 53us/sample - loss: 0.4216 - val_loss: 0.3945\n",
            "Epoch 5/50\n",
            "11610/11610 [==============================] - 1s 51us/sample - loss: 0.4094 - val_loss: 0.3842\n",
            "Epoch 6/50\n",
            "11610/11610 [==============================] - 1s 51us/sample - loss: 0.4006 - val_loss: 0.3761\n",
            "Epoch 7/50\n",
            "11610/11610 [==============================] - 1s 52us/sample - loss: 0.3936 - val_loss: 0.3701\n",
            "Epoch 8/50\n",
            "11610/11610 [==============================] - 1s 51us/sample - loss: 0.3915 - val_loss: 0.3789\n",
            "Epoch 9/50\n",
            "11610/11610 [==============================] - 1s 49us/sample - loss: 0.3872 - val_loss: 0.3631\n",
            "Epoch 10/50\n",
            "11610/11610 [==============================] - 1s 50us/sample - loss: 0.3803 - val_loss: 0.3625\n",
            "Epoch 11/50\n",
            "11610/11610 [==============================] - 1s 50us/sample - loss: 0.3778 - val_loss: 0.3607\n",
            "Epoch 12/50\n",
            "11610/11610 [==============================] - 1s 49us/sample - loss: 0.3746 - val_loss: 0.3579\n",
            "Epoch 13/50\n",
            "11610/11610 [==============================] - 1s 49us/sample - loss: 0.3833 - val_loss: 0.3649\n",
            "Epoch 14/50\n",
            "11610/11610 [==============================] - 1s 49us/sample - loss: 0.3708 - val_loss: 0.3526\n",
            "Epoch 15/50\n",
            "11610/11610 [==============================] - 1s 50us/sample - loss: 0.3832 - val_loss: 0.3625\n",
            "Epoch 16/50\n",
            "11610/11610 [==============================] - 1s 49us/sample - loss: 0.3727 - val_loss: 0.3575\n",
            "Epoch 17/50\n",
            "11610/11610 [==============================] - 1s 50us/sample - loss: 0.3668 - val_loss: 0.3505\n",
            "Epoch 18/50\n",
            "11610/11610 [==============================] - 1s 50us/sample - loss: 0.3633 - val_loss: 0.3498\n",
            "Epoch 19/50\n",
            "11610/11610 [==============================] - 1s 51us/sample - loss: 0.3601 - val_loss: 0.3563\n",
            "Epoch 20/50\n",
            "11610/11610 [==============================] - 1s 52us/sample - loss: 0.3590 - val_loss: 0.3490\n",
            "Epoch 21/50\n",
            "11610/11610 [==============================] - 1s 50us/sample - loss: 0.3598 - val_loss: 0.3463\n",
            "Epoch 22/50\n",
            "11610/11610 [==============================] - 1s 53us/sample - loss: 0.3560 - val_loss: 0.3411\n",
            "Epoch 23/50\n",
            "11610/11610 [==============================] - 1s 49us/sample - loss: 0.3531 - val_loss: 0.3615\n",
            "Epoch 24/50\n",
            "11610/11610 [==============================] - 1s 50us/sample - loss: 0.3551 - val_loss: 0.3381\n",
            "Epoch 25/50\n",
            "11610/11610 [==============================] - 1s 49us/sample - loss: 0.3535 - val_loss: 0.3388\n",
            "Epoch 26/50\n",
            "11610/11610 [==============================] - 1s 51us/sample - loss: 0.3495 - val_loss: 0.3364\n",
            "Epoch 27/50\n",
            "11610/11610 [==============================] - 1s 49us/sample - loss: 0.3487 - val_loss: 0.3640\n",
            "Epoch 28/50\n",
            "11610/11610 [==============================] - 1s 50us/sample - loss: 0.3516 - val_loss: 0.3388\n",
            "Epoch 29/50\n",
            "11610/11610 [==============================] - 1s 50us/sample - loss: 0.3480 - val_loss: 0.3355\n",
            "Epoch 30/50\n",
            "11610/11610 [==============================] - 1s 51us/sample - loss: 0.3449 - val_loss: 0.3513\n",
            "Epoch 31/50\n",
            "11610/11610 [==============================] - 1s 50us/sample - loss: 0.3460 - val_loss: 0.3372\n",
            "Epoch 32/50\n",
            "11610/11610 [==============================] - 1s 50us/sample - loss: 0.3463 - val_loss: 0.3304\n",
            "Epoch 33/50\n",
            "11610/11610 [==============================] - 1s 50us/sample - loss: 0.3427 - val_loss: 0.3279\n",
            "Epoch 34/50\n",
            "11610/11610 [==============================] - 1s 51us/sample - loss: 0.3410 - val_loss: 0.3313\n",
            "Epoch 35/50\n",
            "11610/11610 [==============================] - 1s 51us/sample - loss: 0.3415 - val_loss: 0.3277\n",
            "Epoch 36/50\n",
            "11610/11610 [==============================] - 1s 48us/sample - loss: 0.3415 - val_loss: 0.3297\n",
            "Epoch 37/50\n",
            "11610/11610 [==============================] - 1s 50us/sample - loss: 0.3393 - val_loss: 0.3271\n",
            "Epoch 38/50\n",
            "11610/11610 [==============================] - 1s 50us/sample - loss: 0.3370 - val_loss: 0.3267\n",
            "Epoch 39/50\n",
            "11610/11610 [==============================] - 1s 50us/sample - loss: 0.3368 - val_loss: 0.3279\n",
            "Epoch 40/50\n",
            "11610/11610 [==============================] - 1s 51us/sample - loss: 0.3354 - val_loss: 0.3267\n",
            "Epoch 41/50\n",
            "11610/11610 [==============================] - 1s 49us/sample - loss: 0.3409 - val_loss: 0.3276\n",
            "Epoch 42/50\n",
            "11610/11610 [==============================] - 1s 50us/sample - loss: 0.3370 - val_loss: 0.3220\n",
            "Epoch 43/50\n",
            "11610/11610 [==============================] - 1s 50us/sample - loss: 0.3322 - val_loss: 0.3205\n",
            "Epoch 44/50\n",
            "11610/11610 [==============================] - 1s 50us/sample - loss: 0.3335 - val_loss: 0.3213\n",
            "Epoch 45/50\n",
            "11610/11610 [==============================] - 1s 49us/sample - loss: 0.3320 - val_loss: 0.3230\n",
            "Epoch 46/50\n",
            "11610/11610 [==============================] - 1s 50us/sample - loss: 0.3308 - val_loss: 0.3214\n",
            "Epoch 47/50\n",
            "11610/11610 [==============================] - 1s 49us/sample - loss: 0.3298 - val_loss: 0.3197\n",
            "Epoch 48/50\n",
            "11610/11610 [==============================] - 1s 51us/sample - loss: 0.3293 - val_loss: 0.3194\n",
            "Epoch 49/50\n",
            "11610/11610 [==============================] - 1s 50us/sample - loss: 0.3286 - val_loss: 0.3187\n",
            "Epoch 50/50\n",
            "11610/11610 [==============================] - 1s 49us/sample - loss: 0.3285 - val_loss: 0.3173\n",
            "5160/5160 [==============================] - 0s 30us/sample - loss: 0.3320\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iUuyh8wIHyMK",
        "outputId": "bfa12515-12d8-48ff-b748-45e82ca70afd",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "# fazer uma nova previsão \n",
        "new_house = X_train[0].reshape(1,-1)\n",
        "model.predict(new_house)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[1.299606]], dtype=float32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QgKybZ0t7bQT",
        "outputId": "f1546fed-d60c-46cd-887f-1e2e0d8c12a9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 265
        }
      },
      "source": [
        "# plotar historico \n",
        "pd.DataFrame(history.history).plot();"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXQAAAD4CAYAAAD8Zh1EAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nYII=\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KQOtzc4i8Pml"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}